{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Epinions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: \n",
      "> No. of users: 40163\n",
      "> No. of Books: 139738\n",
      "> No. of Interaction: 664824\n"
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_csv('./ratings_data.txt', sep=' ', names=[\"userId\", \"itemId\", \"rating\"])\n",
    "# Print the number of users, items and interactions\n",
    "print(\"Dataset statistics: \")\n",
    "print(f\"> No. of users: {len(rating_df['userId'].unique())}\")\n",
    "print(f\"> No. of items: {len(rating_df['itemId'].unique())}\")\n",
    "print(f\"> No. of interactions: {rating_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ratings less than 3\n",
    "for i in range(len(rating_df)):\n",
    "    if rating_df.at[i, 'rating'] > 3:\n",
    "        rating_df.at[i, 'rating'] = 1\n",
    "    else: \n",
    "        rating_df.at[i, 'rating'] = 0\n",
    "rating_df.drop(rating_df.index[rating_df['rating'] == 0], axis=0, inplace=True)\n",
    "# Drop the column of 'rating' and duplicate records\n",
    "rating_df.drop('rating', axis=1, inplace=True)\n",
    "rating_df.drop_duplicates(subset =['userId', 'itemId'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  itemId  user_freq  item_freq\n",
      "0            1     100        160          4\n",
      "1            1     101        160          2\n",
      "4            1     103        160          2\n",
      "6            1     105        160          8\n",
      "7            1     106        160        196\n",
      "...        ...     ...        ...        ...\n",
      "664819   49289   30791         13          9\n",
      "664820   49289    3862         13        393\n",
      "664821   49289    3939         13        117\n",
      "664822   49289   60213         13          5\n",
      "664823   49289   62722         13          3\n",
      "\n",
      "[495393 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy rating_df to rdf\n",
    "rdf = copy.copy(rating_df)\n",
    "# Calculate the total number of interactions of every user and item\n",
    "rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "print(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for user and item\n",
    "user_threshold = 9\n",
    "item_threshold = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove users and items where their interactions less than thresholds\n",
    "while (rdf['user_freq'].min() < user_threshold or rdf['item_freq'].min() < item_threshold) :\n",
    "    rdf.drop(rdf.index[rdf['user_freq'] < user_threshold], inplace=True)\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['item_freq'] < item_threshold], inplace=True)\n",
    "    rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total user:  8521\n",
      "total item:  6941\n",
      "sparsity: 0.003188711750071575\n"
     ]
    }
   ],
   "source": [
    "# Show the number of users, items and the sparsity after preprocessing\n",
    "usercnt = len(rdf['userId'].unique())\n",
    "itemcnt = len(rdf['itemId'].unique())\n",
    "print(\"total user: \", usercnt)\n",
    "print(\"total item: \", itemcnt)\n",
    "print('sparsity: ' + str(len(rdf) * 1.0 / (usercnt * itemcnt)))\n",
    "# Drop the column of 'user_freq' and 'item_freq'\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renumber users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188594/188594 [00:04<00:00, 42988.54it/s]\n"
     ]
    }
   ],
   "source": [
    "user_dic = dict()\n",
    "item_dic = dict()\n",
    "\n",
    "user_idx = 0\n",
    "item_idx = 0\n",
    "\n",
    "for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "  if row[1][0] not in user_dic.keys():\n",
    "    user_dic[row[1][0]] = user_idx\n",
    "    user_idx += 1\n",
    "  # add a new book id with an index\n",
    "  if row[1][1] not in item_dic.keys():\n",
    "    item_dic[row[1][1]] = item_idx\n",
    "    item_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188594/188594 [00:04<00:00, 41850.11it/s]\n"
     ]
    }
   ],
   "source": [
    "header = ['userId', 'itemId']\n",
    "with open(f'../../mod_data/{dataset}/{dataset}.csv', 'w', encoding='utf-8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(header)\n",
    "    for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "        try:\n",
    "            writer.writerow([user_dic[row[1][0]], item_dic[row[1][1]]])\n",
    "        except KeyError as e:\n",
    "            print(e, row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "907aeb4e8b69d3749718ea2f018ea403fed4114cf6a38aa67c8afab41dba42e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
