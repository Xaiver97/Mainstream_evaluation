{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'LFM360K'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show statistics of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: \n",
      "> No. of users: 358868\n",
      "> No. of items: 160113\n",
      "> No. of interactions: 17535655\n"
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_csv('./usersha1-artmbid-artname-plays.tsv', sep='\\t', names=[\"userId\", \"itemId\", \"itemName\", \"playcounts\"])\n",
    "# Print the number of users, items and interactions\n",
    "print(\"Dataset statistics: \")\n",
    "print(f\"> No. of users: {len(rating_df['userId'].unique())}\")\n",
    "print(f\"> No. of items: {len(rating_df['itemId'].unique())}\")\n",
    "print(f\"> No. of interactions: {rating_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove abnormal records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535655/17535655 [08:10<00:00, 35729.15it/s]\n"
     ]
    }
   ],
   "source": [
    "nan_list= []\n",
    "for i in tqdm(rating_df.iterrows(), total=rating_df.shape[0]):\n",
    "    if (type(rating_df['itemId'][i[0]]) != type('string')):\n",
    "        nan_list.append(i[0])\n",
    "rating_df.drop(nan_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: \n",
      "> No. of users: 358858\n",
      "> No. of items: 160112\n",
      "> No. of interactions: 17309518\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset statistics: \")\n",
    "print(f\"> No. of users: {len(rating_df['userId'].unique())}\")\n",
    "print(f\"> No. of items: {len(rating_df['itemId'].unique())}\")\n",
    "print(f\"> No. of interactions: {rating_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop playcounts less than 20\n",
    "rating_df.drop(\"itemName\", axis=1, inplace=True)\n",
    "rating_df.drop(rating_df.index[rating_df['playcounts'] < 20], axis=0, inplace=True)\n",
    "# Drop the column of 'playcounts' and duplicate records\n",
    "rating_df.drop('playcounts', axis=1, inplace=True)\n",
    "rating_df.drop_duplicates(subset =['userId', 'itemId'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            userId  \\\n",
      "0         00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "1         00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "2         00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "3         00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "4         00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "...                                            ...   \n",
      "17535629                              sep 20, 2008   \n",
      "17535630                              sep 20, 2008   \n",
      "17535631                              sep 20, 2008   \n",
      "17535632                              sep 20, 2008   \n",
      "17535633                              sep 20, 2008   \n",
      "\n",
      "                                        itemId  user_freq  item_freq  \n",
      "0         3bd73256-3905-4f3a-97e2-8b341527f805         49         83  \n",
      "1         f2fb0ff0-5679-42ec-a55c-15109ce6e320         49       7724  \n",
      "2         b3ae82c2-e60b-4551-a76d-6620f1b456aa         49        716  \n",
      "3         3d6bbeb7-f90e-4d10-b440-e153c0d10b53         49       1264  \n",
      "4         bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8         49       1194  \n",
      "...                                        ...        ...        ...  \n",
      "17535629  e618770f-e994-41c3-856f-1eedf56b6d74         27       6942  \n",
      "17535630  de11b037-d880-40e0-8901-0397c768c457         27       4021  \n",
      "17535631  3798b104-01cb-484c-a3b0-56adc6399b80         27      17507  \n",
      "17535632  680ba421-a0ec-4e68-96c2-5f092a11fe5b         27       1552  \n",
      "17535633  aa7a2827-f74b-473c-bd79-03d065835cf7         27      21246  \n",
      "\n",
      "[14618440 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy rating_df to rdf\n",
    "rdf = copy.copy(rating_df)\n",
    "# Calculate the total number of interactions of every user and item\n",
    "rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "print(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for user and item\n",
    "user_threshold = 50\n",
    "item_threshold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove users and items where their interactions less than threshold\n",
    "while (rdf['user_freq'].min() < user_threshold or rdf['item_freq'].min() < item_threshold) :\n",
    "    rdf.drop(rdf.index[rdf['user_freq'] < user_threshold], inplace=True)\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['item_freq'] < item_threshold], inplace=True)\n",
    "    rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total user:  52966\n",
      "total item:  15263\n",
      "sparsity: 0.0035667806253268397\n"
     ]
    }
   ],
   "source": [
    "# Show the number of users, items and the sparsity after preprocessing\n",
    "usercnt = len(rdf['userId'].unique())\n",
    "itemcnt = len(rdf['itemId'].unique())\n",
    "print(\"total user: \", usercnt)\n",
    "print(\"total item: \", itemcnt)\n",
    "print('sparsity: ' + str(len(rdf) * 1.0 / (usercnt * itemcnt)))\n",
    "# Drop the column of 'user_freq' and 'item_freq'\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renumber users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2883457/2883457 [01:16<00:00, 37806.23it/s]\n"
     ]
    }
   ],
   "source": [
    "user_dic = dict()\n",
    "item_dic = dict()\n",
    "\n",
    "user_idx = 0\n",
    "item_idx = 0\n",
    "\n",
    "for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "  if row[1][0] not in user_dic.keys():\n",
    "    user_dic[row[1][0]] = user_idx\n",
    "    user_idx += 1\n",
    "  # add a new book id with an index\n",
    "  if row[1][1] not in item_dic.keys():\n",
    "    item_dic[row[1][1]] = item_idx\n",
    "    item_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2883457/2883457 [01:20<00:00, 36036.75it/s]\n"
     ]
    }
   ],
   "source": [
    "header = ['userId', 'itemId']\n",
    "with open(f'../../mod_data/{dataset}/{dataset}.csv', 'w', encoding='utf-8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(header)\n",
    "    for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "        try:\n",
    "            writer.writerow([user_dic[row[1][0]], item_dic[row[1][1]]])\n",
    "        except KeyError as e:\n",
    "            print(e, row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "907aeb4e8b69d3749718ea2f018ea403fed4114cf6a38aa67c8afab41dba42e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
