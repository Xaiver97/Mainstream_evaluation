{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'BookCrossing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics: \n",
      "> No. of users: 77805\n",
      "> No. of items: 185973\n",
      "> No. of interactions: 433671\n"
     ]
    }
   ],
   "source": [
    "# Remove all implicit rating records where rating equal to 0\n",
    "rating_df = pd.read_csv('./BX-Book-Ratings.csv', sep=';', names=[\"userId\", \"itemId\", \"rating\"], skiprows=1, encoding='unicode_escape')\n",
    "rating_df.drop(rating_df.index[rating_df['rating'] == 0], axis=0, inplace=True)\n",
    "# Print the number of users, items and interactions\n",
    "print(\"Dataset statistics: \")\n",
    "print(f\"> No. of users: {len(rating_df['userId'].unique())}\")\n",
    "print(f\"> No. of items: {len(rating_df['itemId'].unique())}\")\n",
    "print(f\"> No. of interactions: {rating_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column of 'rating' and duplicate records\n",
    "rating_df.drop('rating', axis=1, inplace=True)\n",
    "rating_df.drop_duplicates(subset =['userId', 'itemId'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userId       itemId  user_freq  item_freq\n",
      "1        276726   0155061224          1          1\n",
      "3        276729   052165615X          2          1\n",
      "4        276729   0521795028          2          1\n",
      "6        276736   3257224281          1          4\n",
      "7        276737   0600570967          1          1\n",
      "...         ...          ...        ...        ...\n",
      "1149773  276704   0806917695          5          1\n",
      "1149775  276704   1563526298          5          3\n",
      "1149777  276709   0515107662          1         18\n",
      "1149778  276721   0590442449          1          2\n",
      "1149779  276723  05162443314          1          1\n",
      "\n",
      "[433671 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy rating_df to rdf\n",
    "rdf = copy.copy(rating_df)\n",
    "# Calculate the total number of interactions of every user and item\n",
    "rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "print(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for user and item\n",
    "user_threshold = 6\n",
    "item_threshold = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove users and items where their interactions less than thresholds\n",
    "while (rdf['user_freq'].min() < user_threshold or rdf['item_freq'].min() < item_threshold) :\n",
    "    rdf.drop(rdf.index[rdf['user_freq'] < user_threshold], inplace=True)\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['item_freq'] < item_threshold], inplace=True)\n",
    "    rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total user:  5107\n",
      "total item:  6515\n",
      "sparsity: 0.002867266738909366\n"
     ]
    }
   ],
   "source": [
    "# Show the number of users, items and the sparsity after preprocessing\n",
    "usercnt = len(rdf['userId'].unique())\n",
    "itemcnt = len(rdf['itemId'].unique())\n",
    "print(\"total user: \", usercnt)\n",
    "print(\"total item: \", itemcnt)\n",
    "print('sparsity: ' + str(len(rdf) * 1.0 / (usercnt * itemcnt)))\n",
    "# Drop the column of 'user_freq' and 'item_freq'\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95400/95400 [00:02<00:00, 37059.49it/s]\n"
     ]
    }
   ],
   "source": [
    "user_dic = dict()\n",
    "item_dic = dict()\n",
    "\n",
    "user_idx = 0\n",
    "item_idx = 0\n",
    "\n",
    "for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "  if row[1][0] not in user_dic.keys():\n",
    "    user_dic[row[1][0]] = user_idx\n",
    "    user_idx += 1\n",
    "  # add a new book id with an index\n",
    "  if row[1][1] not in item_dic.keys():\n",
    "    item_dic[row[1][1]] = item_idx\n",
    "    item_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95400/95400 [00:02<00:00, 34846.76it/s]\n"
     ]
    }
   ],
   "source": [
    "header = ['userId', 'itemId']\n",
    "with open(f'../../mod_data/{dataset}/{dataset}.csv', 'w', encoding='utf-8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(header)\n",
    "    for row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "        try:\n",
    "            writer.writerow([user_dic[row[1][0]], item_dic[row[1][1]]])\n",
    "        except KeyError as e:\n",
    "            print(e, row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "907aeb4e8b69d3749718ea2f018ea403fed4114cf6a38aa67c8afab41dba42e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
